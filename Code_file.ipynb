{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":119874,"databundleVersionId":14372465},{"sourceType":"modelInstanceVersion","sourceId":637077,"databundleVersionId":14418204,"modelInstanceId":480209}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1) Setup\n---\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## a. Libraries and Imports\n\n---\n\n\n","metadata":{}},{"cell_type":"code","source":"# !pip install trackio\n# import trackio","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, mean_squared_error\n\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nimport kagglehub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:06:58.390777Z","iopub.execute_input":"2025-11-10T14:06:58.391032Z","iopub.status.idle":"2025-11-10T14:07:11.427098Z","shell.execute_reply.started":"2025-11-10T14:06:58.391006Z","shell.execute_reply":"2025-11-10T14:07:11.426283Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## b. Data Loaders \n---\n\n","metadata":{}},{"cell_type":"code","source":"class FaceDataset(Dataset):\n    def __init__(self, csv_file, img_dir, transform=None, train=True):\n        self.data = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.train = train\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]    \n        if 'full_path' in row:\n            image_name = os.path.basename(row['full_path'])\n        elif 'id' in row:\n            image_name = str(row['id']) + \".jpg\" \n            \n        image_name = os.path.basename(row['full_path']) if 'full_path' in row else str(row['id'])\n            \n        image_path = os.path.join(self.img_dir, image_name)\n        \n        try:\n            image = Image.open(image_path).convert(\"RGB\")\n        except FileNotFoundError:\n            image = Image.new(\"RGB\", (224, 224), (128, 128, 128)) \n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.train:\n            age = torch.tensor(row[\"age\"], dtype=torch.float32)\n            gender = torch.tensor(row[\"gender\"], dtype=torch.long)\n            return image, age, gender\n        else:\n            return image, row[\"id\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:07:41.289986Z","iopub.execute_input":"2025-11-10T14:07:41.290284Z","iopub.status.idle":"2025-11-10T14:07:41.297334Z","shell.execute_reply.started":"2025-11-10T14:07:41.290261Z","shell.execute_reply":"2025-11-10T14:07:41.296553Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# #    ScratchCNN tranforms & data loaders\n\n\n\n# transform = transforms.Compose([\n#     transforms.Resize((128, 128)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n# ])\n\n# train_img_dir = \"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/train\"\n# df = pd.read_csv(\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/train.csv\")\n\n# train_df, val_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n\n# train_df.to_csv(\"train_split.csv\", index=False)\n# val_df.to_csv(\"val_split.csv\", index=False)\n\n# train_dataset = FaceDataset(\"train_split.csv\", train_img_dir, transform=transform, train=True)\n# val_dataset   = FaceDataset(\"val_split.csv\",   train_img_dir, transform=transform, train=True)\n\n# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n# val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #  preTrained model ke liye transforms & data loaders\n\n\n\n# transform_Pretrained = transforms.Compose([\n#     transforms.Resize((224, 224)), # ResNet needs 224x224\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], \n#                          std=[0.229, 0.224, 0.225])\n# ])\n\n# #adding augmentations to prevent overfitting (since abhi bade pretrained models use kr rhe)\n# train_transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.RandomRotation(10),\n#     transforms.ColorJitter(brightness=0.2, contrast=0.2),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], \n#                          std=[0.229, 0.224, 0.225])\n# ])\n\n\n# train_img_dir = \"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/train\"\n# df = pd.read_csv(\"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/train.csv\")\n\n# train_df, val_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n\n# train_df.to_csv(\"train_split.csv\", index=False)\n# val_df.to_csv(\"val_split.csv\", index=False)\n\n# train_dataset = FaceDataset(\"train_split.csv\", train_img_dir, transform=train_transform, train=True)\n# val_dataset   = FaceDataset(\"val_split.csv\",   train_img_dir, transform=transform_Pretrained, train=True)\n\n# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n# val_loader   = DataLoader(val_dataset,   batch_size=16, shuffle=False, num_workers=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## c. Model Architecture\n\n\n\n\n\n---\n\n","metadata":{}},{"cell_type":"markdown","source":"### c1) Scratch CNN","metadata":{}},{"cell_type":"code","source":"# class ScratchCNN(nn.Module):\n#     def __init__(self):\n#         super(ScratchCNN, self).__init__()\n\n#         self.features = nn.Sequential(\n#             nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n#             nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n#             nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n#         )\n\n#         self.flatten = nn.Flatten()\n\n#         # Input image size 128x128 -> 16x16 feature map (3 max pools)\n#         self.fc = nn.Sequential(\n#             nn.Linear(128 * 16 * 16, 256),\n#             nn.ReLU(),\n#         )\n\n#         self.age_head = nn.Linear(256, 1)        # regression\n#         self.gender_head = nn.Linear(256, 2)     # classification\n\n#     def forward(self, x):\n#         x = self.features(x)\n#         x = self.flatten(x)\n#         x = self.fc(x)\n\n#         age = self.age_head(x)\n#         gender = self.gender_head(x)\n#         return age, gender","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Deeper ScratchCNNv2 with Batch Norm and Dropout\n# class ScratchCNNv2(nn.Module):  \n#     def __init__(self):\n#         super(ScratchCNNv2, self).__init__()\n\n#         self.features = nn.Sequential(\n#             # Block 1: 128 -> 64\n#             nn.Conv2d(3, 32, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(32),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             # Block 2: 64 -> 32\n#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(64),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             # Block 3: 32 -> 16\n#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(128),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             # Block 4: 16 -> 8\n#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(256),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#         )\n\n#         self.flatten = nn.Flatten()\n\n#         # Final feature map size is 8x8 (128 -> 64 -> 32 -> 16 -> 8)\n#         # Final channels = 256\n#         self.fc = nn.Sequential(\n#             nn.Linear(256 * 8 * 8, 512),\n#             nn.ReLU(),\n#             nn.Dropout(0.5), \n#             nn.Linear(512, 256),\n#             nn.ReLU(),\n#             nn.Dropout(0.3)\n#         )\n\n#         # Output heads\n#         self.age_head = nn.Linear(256, 1)      # Regression\n#         self.gender_head = nn.Linear(256, 2)   # Classification\n\n#     def forward(self, x):\n#         x = self.features(x)\n#         x = self.flatten(x)\n#         x = self.fc(x)\n#         age = self.age_head(x)\n#         gender = self.gender_head(x)\n#         return age, gender\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### c2) Finetuned CNN","metadata":{}},{"cell_type":"code","source":"from torchvision import models\n\nclass ResNet34MultiTask(nn.Module):\n    def __init__(self, pretrained=True):\n        super(ResNet34MultiTask, self).__init__()\n        \n        weights = models.ResNet34_Weights.DEFAULT if pretrained else None\n        self.backbone = models.resnet34(weights=weights)\n\n        num_features = self.backbone.fc.in_features  # num. of features in final layer\n        \n        self.backbone.fc = nn.Identity() #final fc layer ko -> Identity layer, so num_fea\n\n        # new multi-task heads\n        self.age_head = nn.Linear(num_features, 1)      # Regression to 1 value\n        self.gender_head = nn.Linear(num_features, 2)   # Classification to 2 values\n\n    def forward(self, x):\n        features = self.backbone(x) #features from backbone\n        \n        # Pass features to each head\n        age = self.age_head(features)\n        gender = self.gender_head(features)\n        \n        return age, gender","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:07:48.108786Z","iopub.execute_input":"2025-11-10T14:07:48.109477Z","iopub.status.idle":"2025-11-10T14:07:48.116785Z","shell.execute_reply.started":"2025-11-10T14:07:48.109443Z","shell.execute_reply":"2025-11-10T14:07:48.115934Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## d. Loss Function, Optimizer, and Metrics\n---\n\n","metadata":{}},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# print(f\"Using device: {device}\")\n\n# criterion_age = nn.MSELoss()\n# criterion_gender = nn.CrossEntropyLoss()\n# GENDER_LOSS_WEIGHT = 50.0 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # == ScratchCNNv2\n# model = ScratchCNNv2().to(device)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # == Resnet34\n\n# model = ResNet34MultiTask(pretrained=True).to(device)\n\n# # Optimizers for 2-Phase Training \n\n# # PHASE 1: Optimizer for the head ONLY\n# head_params = list(model.age_head.parameters()) + list(model.gender_head.parameters())\n# optimizer_head = torch.optim.Adam(head_params, lr=1e-4) \n\n# # PHASE 2: Optimizer for the ENTIRE model\n# optimizer_all = torch.optim.Adam(model.parameters(), lr=1e-5) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Training Code \n\n*(üí° This section should be commented while submitting to prevent re-training)*\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"\n## üß≠a. Trackio Initialization and Logging\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"# # --- Hugging Face Login ---\n# from huggingface_hub import login\n# from kaggle_secrets import UserSecretsClient\n# try:\n#     user_secrets = UserSecretsClient()\n#     secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n#     login(token=secret_value_0)\n#     print(\"Hugging Face login successful.\")\n# except Exception as e:\n#     print(f\"Hugging Face login failed. Error: {e}\")\n\n# # --- Trackio Initialization ---\n# import trackio\n# try:\n#     trackio.init(\n#         project=\"25-t3-nppe1\",\n#         space_id=\"archi29/dlgenai-nppe\",  \n#         group=\"pretrained_1_v3\"\n#     )\n#     print(\"Trackio initialized for Model 3 (ResNet34).\")\n# except Exception as e:\n#     print(f\"Trackio initialization failed: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß©b. Training Execution\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"# print(\"--- Starting Model 2 (ScratchCNNv2) Training ---\")\n\n# epochs = 30 \n# best_val_rmse = float(\"inf\") \n\n# for epoch in range(epochs):\n#     model.train()\n#     total_train_loss = 0\n#     total_train_age_loss = 0\n#     total_train_gender_loss = 0\n\n#     for imgs, ages, genders in train_loader:\n#         imgs, ages, genders = imgs.to(device), ages.to(device), genders.to(device)\n\n#         optimizer.zero_grad()\n#         pred_age, pred_gender = model(imgs)\n\n#         loss_age = criterion_age(pred_age.squeeze(), ages)\n#         loss_gender = criterion_gender(pred_gender, genders)\n        \n#         # loss weighting\n#         loss = loss_age + (GENDER_LOSS_WEIGHT * loss_gender)\n\n#         loss.backward()\n#         optimizer.step()\n\n#         total_train_loss += loss.item()\n#         total_train_age_loss += loss_age.item()\n#         total_train_gender_loss += loss_gender.item()\n\n#     # Validation with Competition Metrics (RMSE, F1)\n#     model.eval()\n#     total_val_loss = 0\n    \n#     # Lists to store all predictions and ground truths for metric calculation\n#     all_age_preds = []\n#     all_age_gts = []\n#     all_gender_preds = []\n#     all_gender_gts = []\n\n#     with torch.no_grad():\n#         for imgs, ages, genders in val_loader:\n#             imgs, ages, genders = imgs.to(device), ages.to(device), genders.to(device)\n\n#             pred_age, pred_gender = model(imgs)\n\n#             loss_age = criterion_age(pred_age.squeeze(), ages)\n#             loss_gender = criterion_gender(pred_gender, genders)\n#             loss = loss_age + (GENDER_LOSS_WEIGHT * loss_gender)\n#             total_val_loss += loss.item()\n\n#             # Store predictions and ground truths for metrics\n#             all_age_preds.append(pred_age.squeeze().cpu())\n#             all_age_gts.append(ages.cpu())\n#             all_gender_preds.append(pred_gender.argmax(dim=1).cpu())\n#             all_gender_gts.append(genders.cpu())\n\n#     # Calculate Metrics for the Epoch\n#     avg_train_loss = total_train_loss / len(train_loader)\n#     avg_val_loss = total_val_loss / len(val_loader)\n    \n#     # Calculate separate train losses for logging\n#     avg_train_age_loss = total_train_age_loss / len(train_loader)\n#     avg_train_gender_loss = total_train_gender_loss / len(train_loader)\n\n#     # Concatenate all batches\n#     age_preds_tensor = torch.cat(all_age_preds)\n#     age_gts_tensor = torch.cat(all_age_gts)\n#     gender_preds_tensor = torch.cat(all_gender_preds)\n#     gender_gts_tensor = torch.cat(all_gender_gts)\n\n#     # Calculate RMSE and Macro F1\n#     val_rmse = np.sqrt(mean_squared_error(age_gts_tensor.numpy(), age_preds_tensor.numpy()))\n#     val_macro_f1 = f1_score(gender_gts_tensor.numpy(), gender_preds_tensor.numpy(), average='macro')\n\n#     print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val RMSE: {val_rmse:.4f} | Val F1: {val_macro_f1:.4f}\")\n#     print(f\"  [Losses] Train Age: {avg_train_age_loss:.2f}, Train Gender: {avg_train_gender_loss:.2f}\")\n\n#     # --- Trackio Logging ---\n#     trackio.log({\n#         \"epoch\": epoch + 1,\n#         \"train_loss_total\": avg_train_loss,\n#         \"train_loss_age\": avg_train_age_loss,\n#         \"train_loss_gender\": avg_train_gender_loss,\n#         \"val_loss_total\": avg_val_loss,\n#         \"val_rmse\": val_rmse,          # Log the competition metric\n#         \"val_macro_f1\": val_macro_f1   # Log the competition metric\n#     })\n\n#     # Save Best Model \n#     if val_rmse < best_val_rmse:\n#         best_val_rmse = val_rmse\n#         torch.save(model.state_dict(), \"cnn_scratch2.pth\")\n#         print(f\"‚úÖ Best model updated (RMSE: {best_val_rmse:.4f}) and saved to 'cnn_scratch2.pth'\")\n\n# print(\"--- Training finished ---\")\n# trackio.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"--- Starting Model 3 (ResNet34) 2-Phase Training ---\")\n\n# PHASE1_EPOCHS = 5     \n# PHASE2_EPOCHS = 25    \n# # Total epochs = 30\n\n# # Early Stopping Parameters\n# PATIENCE = 7         \n# early_stop_counter = 0\n# best_val_rmse = float(\"inf\")\n\n# total_epochs = PHASE1_EPOCHS + PHASE2_EPOCHS\n\n# for epoch in range(total_epochs):\n    \n#     #2-Phase Training Logic\n#     if epoch < PHASE1_EPOCHS:\n#         # PHASE 1: Only train Head\n#         print(f\"--- Epoch {epoch+1}/{total_epochs} [Phase 1: Training Head] ---\")\n#         model.train() #freeze backbone\n#         model.backbone.eval()   \n#         optimizer = optimizer_head\n    \n#     elif epoch == PHASE1_EPOCHS:\n#         # PHASE 2: Unfreeze All \n#         print(f\"--- Epoch {epoch+1}/{total_epochs} [Phase 2: Unfreezing All Layers] ---\")\n#         model.train() \n#         optimizer = optimizer_all\n    \n#     else:\n#         # PHASE 2: Fine-Tuning \n#         print(f\"--- Epoch {epoch+1}/{total_epochs} [Phase 2: Fine-Tuning All] ---\")\n#         model.train()\n#         optimizer = optimizer_all\n    \n    \n#     total_train_loss = 0\n#     total_train_age_loss = 0\n#     total_train_gender_loss = 0\n\n#     # Training Batch Loop \n#     for imgs, ages, genders in train_loader:\n#         imgs, ages, genders = imgs.to(device), ages.to(device), genders.to(device)\n\n#         optimizer.zero_grad()\n#         pred_age, pred_gender = model(imgs)\n\n#         loss_age = criterion_age(pred_age.squeeze(), ages)\n#         loss_gender = criterion_gender(pred_gender, genders)\n        \n#         loss = loss_age + (GENDER_LOSS_WEIGHT * loss_gender)\n        \n#         loss.backward()\n#         optimizer.step()\n\n#         total_train_loss += loss.item()\n#         total_train_age_loss += loss_age.item()\n#         total_train_gender_loss += loss_gender.item()\n\n#     #Validation with Competition Metrics (RMSE, F1)\n#     model.eval() \n#     total_val_loss = 0\n    \n#     all_age_preds = []\n#     all_age_gts = []\n#     all_gender_preds = []\n#     all_gender_gts = []\n\n#     with torch.no_grad():\n#         for imgs, ages, genders in val_loader:\n#             imgs, ages, genders = imgs.to(device), ages.to(device), genders.to(device)\n#             pred_age, pred_gender = model(imgs)\n\n#             loss_age = criterion_age(pred_age.squeeze(), ages)\n#             loss_gender = criterion_gender(pred_gender, genders)\n#             loss = loss_age + (GENDER_LOSS_WEIGHT * loss_gender)\n#             total_val_loss += loss.item()\n\n#             all_age_preds.append(pred_age.squeeze().cpu())\n#             all_age_gts.append(ages.cpu())\n#             all_gender_preds.append(pred_gender.argmax(dim=1).cpu())\n#             all_gender_gts.append(genders.cpu())\n\n#     # Metrics for the Epoch \n#     avg_train_loss = total_train_loss / len(train_loader)\n#     avg_val_loss = total_val_loss / len(val_loader)\n#     avg_train_age_loss = total_train_age_loss / len(train_loader)\n#     avg_train_gender_loss = total_train_gender_loss / len(train_loader)\n\n#     age_preds_tensor = torch.cat(all_age_preds)\n#     age_gts_tensor = torch.cat(all_age_gts)\n#     gender_preds_tensor = torch.cat(all_gender_preds)\n#     gender_gts_tensor = torch.cat(all_gender_gts)\n\n#     val_rmse = np.sqrt(mean_squared_error(age_gts_tensor.numpy(), age_preds_tensor.numpy()))\n#     val_macro_f1 = f1_score(gender_gts_tensor.numpy(), gender_preds_tensor.numpy(), average='macro')\n\n#     print(f\"Epoch {epoch+1}/{total_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val RMSE: {val_rmse:.4f} | Val F1: {val_macro_f1:.4f}\")\n#     print(f\"  [Losses] Train Age: {avg_train_age_loss:.2f}, Train Gender: {avg_train_gender_loss:.2f}\")\n\n#     # --- Trackio Logging ---\n#     trackio.log({\n#         \"epoch\": epoch + 1,\n#         \"train_loss_total\": avg_train_loss,\n#         \"train_loss_age\": avg_train_age_loss,\n#         \"train_loss_gender\": avg_train_gender_loss,\n#         \"val_loss_total\": avg_val_loss,\n#         \"val_rmse\": val_rmse,\n#         \"val_macro_f1\": val_macro_f1,\n#         \"phase\": 1 if epoch < PHASE1_EPOCHS else 2\n#     })\n\n#     # Early Stopping & Save Best Model\n#     if val_rmse < best_val_rmse:\n#         best_val_rmse = val_rmse\n#         torch.save(model.state_dict(), \"Pretrained_1.pth\")\n#         print(f\"‚úÖ Best model updated (RMSE: {best_val_rmse:.4f}) and saved to 'Pretrained_1.pth'\")\n#         early_stop_counter = 0 \n#     else:\n#         early_stop_counter += 1\n#         print(f\"‚ö†Ô∏è No improvement in Val RMSE for {early_stop_counter} epoch(s). Best RMSE: {best_val_rmse:.4f}\")\n\n#     if early_stop_counter >= PATIENCE:\n#         print(f\"--- üõë Early stopping triggered after {epoch + 1} epochs. ---\")\n#         break \n\n# print(\"--- Training finished ---\")\n# trackio.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üì§c. Upload Trained Model to KaggleHub\n\n---\n","metadata":{}},{"cell_type":"code","source":"# print(\"--- Uploading Model 2 to KaggleHub ---\")\n\n# handle = \"archie29/cnn_scratch2/pytorch/variation1\" \n# local_model_path = \"cnn_scratch2.pth\"\n\n# try:\n#     kagglehub.model_upload(handle, \n#                            local_model_path, \n#                            version_notes=\"Second scratch CNN (v2) with BN, Dropout, and balanced loss.\")\n#     print(f\"Successfully uploaded model to {handle}\")\n# except Exception as e:\n#     print(f\"Model upload failed: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"[ScratchCNN2](https://www.kaggle.com/models/archie29/cnn_scratch2/pytorch/variation1)","metadata":{}},{"cell_type":"code","source":"# print(\"--- Uploading Model 3 to KaggleHub ---\")\n\n# handle = \"archie29/Pretrained_1/pytorch/variation1\" \n# local_model_path = \"Pretrained_1.pth\"\n\n# try:\n#     kagglehub.model_upload(handle, \n#                            local_model_path, \n#                            version_notes=\"Model 3 -- v2: Trained with fixed LR (1e-4) and 2-phase training.\")\n#     print(f\"Successfully uploaded model to {handle}\")\n# except Exception as e:\n#     print(f\"Model upload failed: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"[Model3V1](https://www.kaggle.com/models/archie29/Pretrained_1/pytorch/variation1)\n\n\n[Model3V2](https://www.kaggle.com/models/archie29/Pretrained_1/pytorch/variation1)","metadata":{}},{"cell_type":"markdown","source":"# üîç3. Inference code\n---\n","metadata":{}},{"cell_type":"markdown","source":"## üì•a. Load Uploaded Model from KaggleHub\n---\n\n","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nMODEL_HANDLE = \"archie29/Pretrained_1/pytorch/variation1\" \nMODEL_FILE_NAME = \"Pretrained_1.pth\"\n\nprint(f\"Loading model from {MODEL_HANDLE}...\")\ntry:\n    model_dir = kagglehub.model_download(MODEL_HANDLE)\n    model_path = os.path.join(model_dir, MODEL_FILE_NAME)\n    model = ResNet34MultiTask() \n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n    print(\"Model loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    model = None \n    print(\"WARNING: Using a dummy model. Predictions will be random.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:08:11.793112Z","iopub.execute_input":"2025-11-10T14:08:11.793429Z","iopub.status.idle":"2025-11-10T14:08:17.007851Z","shell.execute_reply.started":"2025-11-10T14:08:11.793402Z","shell.execute_reply":"2025-11-10T14:08:17.007024Z"}},"outputs":[{"name":"stdout","text":"Loading model from archie29/Pretrained_1/pytorch/variation1...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 93.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#Test DataLoader \ntest_img_dir = \"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/test\"\ntest_csv = \"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset/test.csv\"\n\ntransform_Pretrained = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = FaceDataset(test_csv, test_img_dir, transform=transform_Pretrained, train=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\nprint(f\"Test DataLoader created with {len(test_dataset)} images.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:08:20.381986Z","iopub.execute_input":"2025-11-10T14:08:20.382285Z","iopub.status.idle":"2025-11-10T14:08:20.415721Z","shell.execute_reply.started":"2025-11-10T14:08:20.382262Z","shell.execute_reply":"2025-11-10T14:08:20.415122Z"}},"outputs":[{"name":"stdout","text":"Test DataLoader created with 8677 images.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## üìàb. Test Prediction / Inference  \n\n---\n\n","metadata":{}},{"cell_type":"code","source":"print(\"--- Starting Inference for Model 3 (ResNet34) ---\")\nall_ids = []\nall_ages = []\nall_genders = []\n\nif model is not None:\n    with torch.no_grad():\n        for imgs, ids in test_loader:\n            imgs = imgs.to(device)\n            \n            pred_age, pred_gender = model(imgs)\n            \n            ages_batch = pred_age.squeeze().cpu().numpy()\n            genders_batch = pred_gender.argmax(dim=1).cpu().numpy()\n\n            all_ids.extend(ids.numpy()) \n            all_ages.extend(ages_batch)\n            all_genders.extend(genders_batch)\nelse:\n    print(\"Generating random predictions as model failed to load.\")\n    all_ids = list(pd.read_csv(test_csv)['id'])\n    all_ages = np.random.uniform(20, 50, len(all_ids))\n    all_genders = np.random.randint(0, 2, len(all_ids))\n\n\nprint(\"Creating submission file...\")\nsubmission_df = pd.DataFrame({\n    \"id\": all_ids,\n    \"age\": all_ages,\n    \"gender\": all_genders\n})\n\n# Post-processing\nsubmission_df[\"age\"] = submission_df[\"age\"].clip(0) \nsubmission_df[\"age\"] = np.round(submission_df[\"age\"], 1) \nsubmission_df[\"gender\"] = submission_df[\"gender\"].astype(int) \n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv created successfully!\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:09:36.057503Z","iopub.execute_input":"2025-11-10T14:09:36.058131Z","iopub.status.idle":"2025-11-10T14:09:58.695063Z","shell.execute_reply.started":"2025-11-10T14:09:36.058100Z","shell.execute_reply":"2025-11-10T14:09:58.694281Z"}},"outputs":[{"name":"stdout","text":"--- Starting Inference for Model 3 (ResNet34) ---\nCreating submission file...\nsubmission.csv created successfully!\n   id        age  gender\n0   0  36.299999       1\n1   1  31.900000       0\n2   2  23.900000       1\n3   3  33.200001       1\n4   4  61.200001       1\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}